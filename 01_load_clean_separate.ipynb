{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94379c4",
   "metadata": {},
   "source": [
    "## Cellule 1 – imports & chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909ef6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(Path(\"..\") / \"src\"))\n",
    "from utils_text import fix_mojibake, clean_text, is_retweet_from_text\n",
    "\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "INT_DIR = Path(\"../data/interim\")\n",
    "INT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c51189",
   "metadata": {},
   "source": [
    "## Cellule 2 – fonction de lecture robuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc24c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweets_csv(path: Path) -> pd.DataFrame:\n",
    "    date_cols = ['created_at', 'user_join_date', 'collected_at']\n",
    "    \n",
    "    # Lire TOUT comme texte d'abord\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            dtype=str,                # tout en texte\n",
    "            keep_default_na=False,\n",
    "            na_values=['', 'NA', 'NaN'],\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\"\n",
    "        )\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            dtype=str,\n",
    "            encoding='latin-1',\n",
    "            keep_default_na=False,\n",
    "            na_values=['', 'NA', 'NaN'],\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\"\n",
    "        )\n",
    "    \n",
    "    # Convertir les numériques APRÈS lecture\n",
    "    numeric_cols = ['likes', 'retweet_count', 'user_followers_count', 'lat', 'long']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convertir les dates\n",
    "    for c in date_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors='coerce', utc=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26e04b",
   "metadata": {},
   "source": [
    "## Cellule 3 – fonction de nettoyage pour UN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d133ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_single_candidate(path_in: Path,\n",
    "                           path_all_out: Path,\n",
    "                           path_nort_out: Path,\n",
    "                           target_label: str):\n",
    "    \"\"\"\n",
    "    Lit un CSV de tweets, nettoie les données\n",
    "    et sauvegarde deux fichiers :\n",
    "      - *_all.parquet : avec retweets\n",
    "      - *_nort.parquet : sans retweets\n",
    "    \"\"\"\n",
    "    # 1) lecture brute + types\n",
    "    df = read_tweets_csv(path_in)\n",
    "    \n",
    "    # 2) garantir les colonnes attendues et l'ordre\n",
    "    expected_cols = [\n",
    "        \"created_at\",\"tweet_id\",\"tweet\",\"likes\",\"retweet_count\",\"source\",\n",
    "        \"user_id\",\"user_name\",\"user_screen_name\",\"user_description\",\"user_join_date\",\n",
    "        \"user_followers_count\",\"user_location\",\"lat\",\"long\",\"city\",\"country\",\"continent\",\n",
    "        \"state\",\"state_code\",\"collected_at\"\n",
    "    ]\n",
    "    for c in expected_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    df = df[expected_cols]\n",
    "    \n",
    "    # 3) ajouter le label candidat\n",
    "    df[\"target\"] = target_label   # \"Trump\" ou \"Biden\"\n",
    "    \n",
    "    # 4) corrections d’encodage sur le texte\n",
    "    text_cols = [\"tweet\",\"user_description\",\"user_name\",\"user_screen_name\",\n",
    "                 \"user_location\",\"city\",\"country\",\"state\",\"continent\",\"source\"]\n",
    "    for c in text_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(fix_mojibake)\n",
    "    for c in [\"user_description\", \"user_location\", \"city\", \"country\", \"state\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(clean_text)  # ou une variante plus légère\n",
    "\n",
    "    \n",
    "    # 5) texte nettoyé + flag retweet\n",
    "    df[\"text_clean\"] = df[\"tweet\"].apply(clean_text)\n",
    "    df[\"is_retweet\"] = df[\"tweet\"].apply(is_retweet_from_text)\n",
    "    \n",
    "    # 6) tri, suppression des doublons\n",
    "    df = df.sort_values(\"created_at\").drop_duplicates(subset=[\"tweet_id\"])\n",
    "    df = df.dropna(subset=[\"user_name\", \"user_location\"])\n",
    "    df = df[(df[\"user_name\"] != \"\") & (df[\"user_location\"] != \"\")]\n",
    "    \n",
    "    # 7) filtrage sans retweets\n",
    "    df_nort = df[~df[\"is_retweet\"]].copy()\n",
    "\n",
    "    # remplacer le texte brut par le texte propre dans les fichiers nettoyés\n",
    "    df[\"tweet_original\"] = df[\"tweet\"]\n",
    "    df[\"tweet\"] = df[\"text_clean\"]\n",
    "    \n",
    "    df_nort[\"tweet_original\"] = df_nort[\"tweet\"]\n",
    "    df_nort[\"tweet\"] = df_nort[\"text_clean\"]\n",
    "\n",
    "    \n",
    "    # 8) sauvegarde\n",
    "    df.to_csv(path_all_out,\n",
    "              index=False,\n",
    "              encoding=\"utf-8-sig\",\n",
    "              sep=\";\")\n",
    "\n",
    "    df_nort.to_csv(path_nort_out,\n",
    "                   index=False,\n",
    "                   encoding=\"utf-8-sig\",\n",
    "                   sep=\";\")\n",
    "\n",
    "    print(f\"{target_label}: {len(df)} tweets, {len(df_nort)} sans retweets\")\n",
    "    return df, df_nort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df849d",
   "metadata": {},
   "source": [
    "## Cellule 4 – appliquer à Trump et à Biden (séparément)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3e4765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump: 671831 tweets, 671696 sans retweets\n",
      "Biden: 539025 tweets, 538925 sans retweets\n"
     ]
    }
   ],
   "source": [
    "# Trump\n",
    "df_trump_all, df_trump_nort = clean_single_candidate(\n",
    "    path_in       = RAW_DIR / \"hashtag_donaldtrump.csv\",\n",
    "    path_all_out  = INT_DIR / \"trump_all.csv\",\n",
    "    path_nort_out = INT_DIR / \"trump_nort.csv\",\n",
    "    target_label  = \"Trump\",\n",
    ")\n",
    "\n",
    "# Biden\n",
    "df_biden_all, df_biden_nort = clean_single_candidate(\n",
    "    path_in       = RAW_DIR / \"hashtag_joebiden.csv\",\n",
    "    path_all_out  = INT_DIR / \"biden_all.csv\",\n",
    "    path_nort_out = INT_DIR / \"biden_nort.csv\",\n",
    "    target_label  = \"Biden\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e53c4b",
   "metadata": {},
   "source": [
    "## Cellule 5 – petits contrôles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3535282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  elecciones2020 en florida joebiden dice que do...   \n",
      "2  trump as a student i used to hear for years fo...   \n",
      "\n",
      "                                          text_clean  is_retweet  \n",
      "0  elecciones2020 en florida joebiden dice que do...       False  \n",
      "2  trump as a student i used to hear for years fo...       False  \n",
      "                                               tweet  \\\n",
      "0  elecciones2020 en florida joebiden dice que do...   \n",
      "2  user user user this is how biden made his trum...   \n",
      "\n",
      "                                          text_clean  is_retweet  \n",
      "0  elecciones2020 en florida joebiden dice que do...       False  \n",
      "2  user user user this is how biden made his trum...       False  \n",
      "Trump is_retweet (nort) :\n",
      "is_retweet\n",
      "False    671696\n",
      "Name: count, dtype: int64\n",
      "Biden is_retweet (nort) :\n",
      "is_retweet\n",
      "False    538925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Aperçu rapide\n",
    "print(df_trump_all.head(2)[[\"tweet\",\"text_clean\",\"is_retweet\"]])\n",
    "print(df_biden_all.head(2)[[\"tweet\",\"text_clean\",\"is_retweet\"]])\n",
    "\n",
    "# Vérifier qu'il n'y a plus de retweets dans les versions _nort\n",
    "print(\"Trump is_retweet (nort) :\")\n",
    "print(df_trump_nort[\"is_retweet\"].value_counts())\n",
    "\n",
    "print(\"Biden is_retweet (nort) :\")\n",
    "print(df_biden_nort[\"is_retweet\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f2435",
   "metadata": {},
   "source": [
    "code pour verifier si les transformation ont été appliqué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af04e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GLC\\AppData\\Local\\Temp\\ipykernel_33508\\1118938771.py:4: DtypeWarning: Columns (6,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../data/interim/trump_nort.csv\", sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs dans tweet : 0\n",
      "# dans tweet : 0\n",
      "Majuscules dans tweet : 0\n",
      "Ponctuation forte dans tweet : 0\n",
      "Doubles espaces dans tweet : 0\n",
      "user_name manquants : 0 vides : 0\n",
      "user_location manquants : 2 vides : 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"../data/interim/trump_nort.csv\", sep=\";\")\n",
    "\n",
    "# 1) Aucune URL dans tweet\n",
    "URL_RE = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "print(\"URLs dans tweet :\",\n",
    "      df[\"tweet\"].str.contains(URL_RE, regex=True, na=False).sum())\n",
    "\n",
    "# 2) Pas de # dans tweet\n",
    "print(\"# dans tweet :\",\n",
    "      df[\"tweet\"].str.contains(\"#\", na=False).sum())\n",
    "\n",
    "# 3) Tout en minuscules dans tweet\n",
    "print(\"Majuscules dans tweet :\",\n",
    "      df[\"tweet\"].str.contains(r\"[A-Z]\", na=False).sum())\n",
    "\n",
    "# 4) Ponctuation forte supprimée dans tweet\n",
    "print(\"Ponctuation forte dans tweet :\",\n",
    "      df[\"tweet\"].str.contains(r\"[:!\\?,\\.']\", na=False).sum())\n",
    "\n",
    "# 5) Doubles espaces dans tweet\n",
    "print(\"Doubles espaces dans tweet :\",\n",
    "      df[\"tweet\"].str.contains(r\"\\s{2,}\", na=False).sum())\n",
    "\n",
    "# 6) user_name & user_location non nuls / non vides\n",
    "print(\"user_name manquants :\",\n",
    "      df[\"user_name\"].isna().sum(),\n",
    "      \"vides :\",\n",
    "      (df[\"user_name\"] == \"\").sum())\n",
    "\n",
    "print(\"user_location manquants :\",\n",
    "      df[\"user_location\"].isna().sum(),\n",
    "      \"vides :\",\n",
    "      (df[\"user_location\"] == \"\").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9b6ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump brut : 971087\n",
      "Biden brut : 777073\n",
      "Total brut : 1748160\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "\n",
    "df_trump_raw = pd.read_csv(RAW_DIR / \"hashtag_donaldtrump.csv\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df_biden_raw = pd.read_csv(RAW_DIR / \"hashtag_joebiden.csv\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "\n",
    "print(\"Trump brut :\", len(df_trump_raw))\n",
    "print(\"Biden brut :\", len(df_biden_raw))\n",
    "print(\"Total brut :\", len(df_trump_raw) + len(df_biden_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624fa589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GLC\\AppData\\Local\\Temp\\ipykernel_33508\\1567396.py:3: DtypeWarning: Columns (6,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_trump_clean = pd.read_csv(INT_DIR / \"trump_nort.csv\", sep=\";\")\n",
      "C:\\Users\\GLC\\AppData\\Local\\Temp\\ipykernel_33508\\1567396.py:4: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_biden_clean = pd.read_csv(INT_DIR / \"biden_nort.csv\", sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump nettoyé (nort) : 671696\n",
      "Biden nettoyé (nort) : 538925\n",
      "Total nettoyé : 1210621\n"
     ]
    }
   ],
   "source": [
    "INT_DIR = Path(\"../data/interim\")\n",
    "\n",
    "df_trump_clean = pd.read_csv(INT_DIR / \"trump_nort.csv\", sep=\";\")\n",
    "df_biden_clean = pd.read_csv(INT_DIR / \"biden_nort.csv\", sep=\";\")\n",
    "\n",
    "print(\"Trump nettoyé (nort) :\", len(df_trump_clean))\n",
    "print(\"Biden nettoyé (nort) :\", len(df_biden_clean))\n",
    "print(\"Total nettoyé :\", len(df_trump_clean) + len(df_biden_clean))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
